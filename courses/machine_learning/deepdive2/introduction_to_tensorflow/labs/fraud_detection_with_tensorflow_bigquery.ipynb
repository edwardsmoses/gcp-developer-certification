{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baXSFrNwcjAw"
   },
   "source": [
    "# Building a Fraud Detection model on Vertex AI with TensorFlow Enterprise and BigQuery\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "1. Analyze the data in BigQuery.\n",
    "2. Ingest records from BigQuery.\n",
    "3. Preprocess the data.\n",
    "4. Build the model.\n",
    "5. Train the model.\n",
    "6. Evaluate the model.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, you'll directly ingest a [BigQuery](https://cloud.google.com/bigquery/) dataset and train a fraud detection model with TensorFlow Enterprise on [Vertex AI](https://cloud.google.com/vertex-ai).\n",
    "\n",
    "You've also walked through all the steps of building a model. Finally, you learned a bit about how to handle imbalanced classification problems.\n",
    "\n",
    "Each learning objective will correspond to a __#TODO__ in this student lab notebook -- try to complete this notebook first and then review the [solution notebook](../solutions/fraud_detection_with_tensorflow_bigquery.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "994zrOpqXhKr"
   },
   "source": [
    "# Ingest records from BigQuery\n",
    "\n",
    "## Step 1: Import Python packages\n",
    "\n",
    "Run the below cell to import the python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "30u1aAwJWuAw"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "from tensorflow_io.bigquery import BigQueryClient\n",
    "\n",
    "import functools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDhwfNB_aBRw"
   },
   "source": [
    "## Step 2: Define constants\n",
    "\n",
    "Let's next define some constants for use in the project. Change **GCP_PROJECT_ID** to the actual project ID you are using. Go ahead and run new cells as you create them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pkn2diEqXB85"
   },
   "outputs": [],
   "source": [
    "GCP_PROJECT_ID = 'qwiklabs-gcp-00-b1e00ce17168' # Replace with your Project-ID\n",
    "DATASET_GCP_PROJECT_ID = GCP_PROJECT_ID # A copy of the data is saved in the user project\n",
    "DATASET_ID = 'tfe_codelab'\n",
    "TRAIN_TABLE_ID = 'ulb_fraud_detection_train'\n",
    "VAL_TABLE_ID = 'ulb_fraud_detection_val'\n",
    "TEST_TABLE_ID = 'ulb_fraud_detection_test'\n",
    "\n",
    "FEATURES = ['Time','V1','V2','V3','V4','V5','V6','V7','V8','V9','V10','V11','V12','V13','V14','V15','V16','V17','V18','V19','V20','V21','V22','V23','V24','V25','V26','V27','V28','Amount']\n",
    "LABEL='Class'\n",
    "DTYPES=[tf.float64] * len(FEATURES) + [tf.int64]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAizN6ccaTBe"
   },
   "source": [
    "## Step 3: Define helper functions\n",
    "\n",
    "Now, let's define a couple functions. **read_session()** reads data from a BigQuery table. **extract_labels()** is a helper function to separate the label column from the rest, so that the dataset is in the format expected by **keras.model_fit()** later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "cvZhCuT4XCNR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 11:40:43.203881: W tensorflow_io/core/kernels/audio_video_mp3_kernels.cc:271] libmp3lame.so.0 or lame functions are not available\n",
      "2022-05-25 11:40:43.206218: I tensorflow_io/core/kernels/cpu_check.cc:128] Your CPU supports instructions that this TensorFlow IO binary was not compiled to use: AVX2 FMA\n",
      "2022-05-25 11:40:43.353322: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "client = BigQueryClient()\n",
    "\n",
    "def read_session(TABLE_ID):\n",
    "    return client.read_session(\n",
    "        \"projects/\" + GCP_PROJECT_ID, DATASET_GCP_PROJECT_ID, TABLE_ID, DATASET_ID,\n",
    "        FEATURES + [LABEL], DTYPES, requested_streams=2\n",
    ")\n",
    "\n",
    "def extract_labels(input_dict):\n",
    "  features = dict(input_dict)\n",
    "  label = tf.cast(features.pop(LABEL), tf.float64)\n",
    "  return (features, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQ-l3m1Dad40"
   },
   "source": [
    "## Step 4: Ingest data\n",
    "\n",
    "Finally, let's create each dataset and then print the first batch from the training dataset. Note that we have defined a **BATCH_SIZE** of 32. This is an important parameter that will impact the speed and accuracy of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Kh-VevYmXCX9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 11:40:45.756773: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-05-25 11:40:45.851131: E tensorflow/core/framework/dataset.cc:552] Unimplemented: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-05-25 11:40:45.851185: E tensorflow/core/framework/dataset.cc:556] Unimplemented: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'Amount': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])>,\n",
       "  'Time': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       "  array([ 282.,  380.,  430.,  711.,  804.,  820.,  912., 1193., 1443.,\n",
       "         1444., 1444., 1840., 1888., 2291., 2371., 2519., 2549., 2741.,\n",
       "         2812., 2827., 2870., 2891., 2989., 3003., 3046., 3105., 3186.,\n",
       "         3204., 3224., 3275., 3330., 3371.])>,\n",
       "  'V1': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       "  array([-0.35646619, -1.29983679, -1.86025769, -0.43134934,  1.18169674,\n",
       "         -0.93748131,  1.08300282,  1.13064571,  1.07669965,  1.04095773,\n",
       "         -0.96040277, -4.10236268, -1.9271414 ,  1.22554941, -0.87883341,\n",
       "         -0.70749537, -0.97164965,  1.33214151, -0.63340299, -0.70659816,\n",
       "         -0.46060238, -1.35641041, -0.46917279, -0.94424503,  1.14151696,\n",
       "         -1.04345577,  1.12683746,  1.08259865, -1.36214557,  1.06316179,\n",
       "         -0.37790788, -1.2367661 ])>,\n",
       "  'V10': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       "  array([-0.05994322,  0.24197886, -0.3716215 ,  0.02222414,  0.55421587,\n",
       "         -0.66669886,  0.45323987,  0.62316477,  0.40661021,  0.59564001,\n",
       "          0.27707224,  0.50882179,  3.43128192,  0.63575496,  1.09738839,\n",
       "          1.71069625, -0.47896858, -1.00427397,  0.3082976 , -0.22974152,\n",
       "         -0.00637609,  0.55201033,  1.60681604,  0.3449355 ,  0.46759979,\n",
       "          0.06858883,  0.46913217,  0.46942833,  0.35552327,  0.62523327,\n",
       "          0.03772551,  0.83113723])>,\n",
       "  'V11': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       "  array([-0.50827023,  0.1449733 ,  0.85974116, -0.99367433, -0.72922734,\n",
       "         -0.34374585, -0.75502041,  0.11159088, -0.99983721,  1.0947233 ,\n",
       "         -1.10968171, -1.43621532, -1.78620734,  0.4399499 , -0.55329979,\n",
       "          0.10668952, -0.50188941, -0.26745841, -1.20499231, -0.85855977,\n",
       "         -0.98672424, -0.33686896,  1.41744216, -0.68310294, -1.57986712,\n",
       "         -1.97688554, -0.81207251, -0.8490156 ,  1.17791925,  0.63441894,\n",
       "         -0.92223528,  0.91394453])>,\n",
       "  'V12': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       "  array([ 4.25506043e-01, -5.83891284e-01,  3.72608840e-01,  2.44681424e-01,\n",
       "         -1.06978368e-02, -4.29063633e-01,  1.84040526e-01,  5.03149220e-01,\n",
       "          1.02691175e-03,  1.35093916e+00, -2.73956038e-01,  2.70510146e-01,\n",
       "         -8.19707673e-01,  9.32767242e-01, -2.17590843e-01,  9.64331119e-02,\n",
       "         -3.72918903e-01,  7.01394900e-01, -4.74707809e-01,  2.44542781e-01,\n",
       "         -2.58522497e-01,  8.70989119e-02,  5.57806010e-01,  1.40084480e-01,\n",
       "         -3.27112595e-01,  3.99601577e-02,  6.10108114e-01, -1.09094822e-01,\n",
       "          8.02265539e-01,  7.16235194e-01,  4.45035101e-01,  1.25372626e-01])>,\n",
       "  'V13': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       "  array([ 0.41430924, -1.59534531, -1.24018477,  0.71184559, -0.01358609,\n",
       "         -1.32585737, -0.10756875,  0.72732949, -0.77044275,  0.70927889,\n",
       "         -0.65390091, -0.31626221, -0.50484945,  1.70431831, -0.08493166,\n",
       "          1.33525991, -0.5225702 , -0.18166553, -0.65406356,  0.30923723,\n",
       "         -0.16253322,  0.31354802,  0.10722606,  0.50272806, -0.40356346,\n",
       "          0.78537593,  0.87327887, -0.6587424 ,  0.15983721, -0.22504451,\n",
       "          1.06112921, -1.15851004])>,\n",
       "  'V14': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       "  array([-0.69837527,  0.03261289,  0.99839133, -0.66697304, -0.27233044,\n",
       "          0.10021293, -0.36109129,  0.17435777, -0.35409441, -0.34398776,\n",
       "         -0.06502001,  0.65507928, -2.8811469 , -0.13194556, -0.7812748 ,\n",
       "         -0.55414466,  0.19560891,  0.15029504, -0.47459911, -0.62970755,\n",
       "         -0.41170931, -0.78660938, -1.04025052, -0.64574778, -0.32305347,\n",
       "         -0.75231541, -0.58067659, -0.2514009 , -0.19754   , -0.16622938,\n",
       "         -0.74459237, -0.07782798])>,\n",
       "  'V15': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       "  array([-1.46534865,  0.75283386, -0.34638713, -0.60026672, -0.11482267,\n",
       "         -0.14388643, -0.03724729,  0.68488322, -0.57371056, -0.83634878,\n",
       "          0.18524572,  0.27211691, -0.7506234 ,  0.33531951, -0.29057938,\n",
       "          1.43992468,  0.79088482,  0.64691016, -0.42841779, -1.1279856 ,\n",
       "         -0.78113727,  0.20686103, -0.3767148 ,  0.16656755,  0.07176431,\n",
       "         -1.01406513, -0.39464596,  0.0232259 , -0.0816889 , -0.70376954,\n",
       "         -0.63387008, -0.29040163])>,\n",
       "  'V16': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       "  array([-0.11900863, -0.09428637, -0.39167858,  0.48020412,  0.94745099,\n",
       "         -0.61343446,  0.33432119,  0.29341232,  0.07897537,  0.48931805,\n",
       "         -0.55937202, -0.07209755, -0.96820707,  1.2218528 , -0.16275343,\n",
       "         -0.62645647,  0.30408707, -0.63447096,  0.53665148,  0.70398707,\n",
       "          1.12921573, -0.24855437, -0.29457385, -0.04499953,  0.59902303,\n",
       "          1.02725474,  0.58160141,  0.36017563, -0.3043922 ,  0.63078501,\n",
       "          0.47860693, -0.00773052])>,\n",
       "  'V17': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       "  array([-0.14473501, -0.16342702,  0.34828943, -0.4385818 , -0.91465513,\n",
       "          0.13066535, -0.1296146 , -0.2884193 ,  0.12216634, -0.4329002 ,\n",
       "          0.95490422,  1.38251524, -0.08862814, -1.19219729, -0.32411633,\n",
       "         -0.06771088, -0.45584511, -0.32401695, -0.38065462, -0.62946527,\n",
       "         -1.18532166,  0.13688233, -0.31986923,  0.10246335, -0.4086114 ,\n",
       "         -1.0308312 , -0.46279329, -0.09811811,  0.32049325, -0.49462676,\n",
       "         -0.46253961,  0.17903308])>,\n",
       "  'V18': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       "  array([-1.33222125, -1.11117601,  0.28212477, -0.11947467,  0.24524423,\n",
       "         -0.98896903, -0.63384776, -0.95250264, -0.81283136, -0.24807311,\n",
       "         -0.40846135, -0.34707278,  0.37465554,  0.19438569,  0.49009035,\n",
       "         -0.63069105, -0.32425728,  0.0221777 ,  0.02865054, -0.28309058,\n",
       "          0.33480673, -0.58480576, -0.0922211 , -0.48095827, -0.30675948,\n",
       "          0.12151958, -0.3029369 , -0.56622537, -0.31455512, -0.02020765,\n",
       "         -0.17026937,  0.19516501])>,\n",
       "  'V19': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       "  array([-1.54744049, -1.12402459,  1.16589317, -0.68153861, -0.46955043,\n",
       "         -0.82991152, -1.1995778 , -1.4915897 , -0.96220373, -0.91505237,\n",
       "          0.85558505,  0.85596078,  1.4734441 , -0.48939622,  1.87611895,\n",
       "          0.43510187, -0.19019744,  1.29814633, -0.68796943, -1.6498877 ,\n",
       "         -1.07207638, -0.3743779 ,  0.09022863, -0.33937436, -0.88088174,\n",
       "         -1.06026316, -0.84780598, -1.1958565 , -0.0767105 , -0.78563131,\n",
       "         -0.709439  ,  0.17599459])>,\n",
       "  'V2': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       "  array([ 0.72541752,  0.88181746, -0.62985892,  1.02769437, -0.00790838,\n",
       "          0.4016488 ,  0.20158881,  0.62539081,  0.1363187 ,  0.21609188,\n",
       "          1.35531589,  0.80980718,  1.36822007,  0.22918716,  0.13365703,\n",
       "          1.63448376,  1.01160241, -0.43984568,  0.96361604,  0.97452316,\n",
       "          0.39932808,  0.43482766,  0.74557436,  0.82488675,  0.14729561,\n",
       "          0.9654235 ,  0.31962665,  0.16165874, -0.01436721,  0.13556853,\n",
       "          0.98753297,  1.15115744])>,\n",
       "  'V20': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       "  array([-0.13360212,  0.06597901,  0.32044963, -0.05788638, -0.04038237,\n",
       "         -0.05640907, -0.20372614, -0.15305984, -0.25381615, -0.13482325,\n",
       "          0.08061935, -0.37665154,  0.82785671,  0.0136616 ,  0.17336796,\n",
       "          0.22649325, -0.09844013, -0.02278778, -0.17498476, -0.17885861,\n",
       "         -0.0448926 , -0.09755355,  0.10464555, -0.10515867, -0.20547863,\n",
       "         -0.3857625 , -0.11040198, -0.23904012,  0.26580662, -0.18778799,\n",
       "         -0.03433264, -0.29903023])>,\n",
       "  'V21': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       "  array([ 2.08037897e-02, -2.72562732e-01,  2.68027796e-01,  1.24133755e-03,\n",
       "         -1.39919855e-01, -1.75749977e-03, -6.04332459e-02, -1.71536437e-02,\n",
       "         -1.82605449e-01,  1.43708659e-03, -1.27067726e-01, -3.03160905e-01,\n",
       "          1.04213526e+00,  1.07430129e-01, -2.96421813e-01,  9.72204479e-02,\n",
       "         -1.76069979e-01, -2.99699393e-01,  1.46755278e-02,  4.36646135e-02,\n",
       "         -2.93323233e-02, -4.95811038e-02,  1.94828601e-02, -1.23018919e-02,\n",
       "         -1.20524873e-01,  7.34568724e-01, -7.69881035e-02, -6.67704061e-02,\n",
       "          1.60140398e-01, -3.13705191e-02,  2.91722507e-04,  8.88290691e-01])>,\n",
       "  'V22': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       "  array([ 0.42431175, -0.36085304,  0.12551524,  0.15417037, -0.39956304,\n",
       "          0.09737922,  0.00964727, -0.01431114, -0.30274329,  0.19537511,\n",
       "         -0.13158667, -0.20173928,  0.21744911,  0.37732036, -0.25548479,\n",
       "          0.40617884, -0.74581758, -0.73022791,  0.01627818,  0.20650435,\n",
       "         -0.2118617 ,  0.2858136 ,  0.57792365,  0.16084741, -0.17989706,\n",
       "         -0.20683751, -0.02597879, -0.03549259,  0.3668555 ,  0.05421847,\n",
       "          0.15722027,  0.08349516])>,\n",
       "  'V23': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       "  array([-0.01598913,  0.22391121, -0.22502854, -0.14153254,  0.01020002,\n",
       "         -0.32405032,  0.07707211,  0.08655949,  0.10353341,  0.0534581 ,\n",
       "         -0.114279  ,  0.50940657, -0.26508949, -0.17914543, -0.58329797,\n",
       "         -0.12376811, -0.15166062, -0.04285287, -0.06146247, -0.09760119,\n",
       "         -0.0525803 ,  0.01993991, -0.10942069,  0.04776313, -0.02190327,\n",
       "         -0.14923283,  0.0360548 ,  0.08368782, -0.02264522,  0.02510466,\n",
       "         -0.12267652,  0.05991002])>,\n",
       "  'V24': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       "  array([ 0.46675445,  0.59892962,  0.58666444,  0.38461019,  0.99223541,\n",
       "          0.4365211 ,  0.07214124,  0.39349612,  0.05474628,  0.04063746,\n",
       "          0.07017066,  0.10363933, -0.42802525, -1.25160632, -1.67751383,\n",
       "          0.1079921 ,  0.36691202,  1.00626374,  0.35519634,  0.7004112 ,\n",
       "          0.97466883,  0.42320574,  0.22682018,  0.08754022, -0.7933081 ,\n",
       "         -0.58113389,  0.40990395,  0.05705059, -0.27173567, -0.31263205,\n",
       "          0.41042972,  0.17919797])>,\n",
       "  'V25': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       "  array([-0.80996201, -0.39770464, -0.03159808, -0.14713247,  0.45701473,\n",
       "          0.50967362,  0.22074665,  0.33206228,  0.2255521 ,  0.22150741,\n",
       "          0.00756984,  0.36561076,  0.50287263,  0.36231696,  0.0505239 ,\n",
       "         -0.6527686 ,  0.12612871,  0.78300616, -0.1790855 , -0.25507381,\n",
       "         -0.15813717,  0.03669853, -0.79885263,  0.17358268,  0.31729654,\n",
       "         -0.31783069,  0.32605328,  0.20209739, -0.04989813,  0.23142133,\n",
       "         -0.10549575, -0.42001089])>,\n",
       "  'V26': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       "  array([ 0.65733442,  0.63714078,  0.57016802, -0.08710014, -0.02792357,\n",
       "          0.45411616, -0.01348303, -0.06637801, -0.05931063, -0.03378516,\n",
       "          0.24504545,  0.30503763,  0.47171972,  1.12163189,  0.25040925,\n",
       "         -0.01127952,  0.0493164 , -0.73663128, -0.10694743, -0.26856218,\n",
       "         -0.23021274,  0.05917137, -0.12318015,  0.10635406,  0.04061577,\n",
       "         -0.21362138, -0.04642032, -0.011636  ,  0.17789828, -0.01027021,\n",
       "         -0.08776131,  0.05057774])>,\n",
       "  'V27': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       "  array([-0.04315019,  0.23487228, -0.04300749,  0.10111688,  0.04527339,\n",
       "         -0.20180428,  0.05859641,  0.01385823,  0.05524265,  0.06066462,\n",
       "          0.26188583,  0.75067142, -0.01004601, -0.03702117, -0.22314912,\n",
       "         -0.9732494 , -0.29756549,  0.06360052, -0.21503926,  0.13108474,\n",
       "          0.08053838, -0.25371562, -0.88054653, -0.17984621,  0.05469806,\n",
       "          0.10675419,  0.04839639,  0.05499326,  0.10856039,  0.05375711,\n",
       "          0.07547911, -0.21193104])>,\n",
       "  'V28': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       "  array([-0.0464014 ,  0.02137879, -0.22373948,  0.07794387,  0.02886818,\n",
       "         -0.17543901,  0.03205391,  0.02538194,  0.02881534,  0.02378202,\n",
       "          0.0932026 , -0.69626666, -0.92700185, -0.00989258, -0.42076351,\n",
       "         -0.28269786,  0.10408841,  0.01660553,  0.0506978 ,  0.14441364,\n",
       "          0.06637588, -0.10517692, -0.58070649, -0.01533235,  0.02247219,\n",
       "          0.16525507,  0.03753244,  0.03087016,  0.09557045,  0.01835066,\n",
       "          0.04461914,  0.14684822])>,\n",
       "  'V3': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       "  array([ 1.97174889,  1.45284188,  0.96657045,  2.67081623, -0.06684539,\n",
       "          1.88268869,  1.49766367,  0.83798713,  1.45956759,  1.53595339,\n",
       "          2.50117134,  0.66710918,  3.493593  ,  0.45074177,  2.5340468 ,\n",
       "          1.90961046,  1.91130314, -1.21306328,  2.49494562,  2.84800225,\n",
       "          0.84709146,  3.17629581,  2.83288095,  2.72191044,  1.14035442,\n",
       "          2.03678839,  1.5459047 ,  1.48620367,  3.01202836,  1.37893826,\n",
       "          2.61129287,  2.65165008])>,\n",
       "  'V4': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       "  array([ 0.83134272, -1.29369833,  0.84463208,  2.08478704,  1.53222302,\n",
       "         -0.36200091,  2.661922  ,  2.50654261,  2.7542053 ,  2.53650724,\n",
       "          3.03648846,  3.49495604,  2.62321107,  1.22302692,  2.60981069,\n",
       "          2.5838095 , -0.27286732, -1.79751399,  2.09905099,  1.62437481,\n",
       "          0.58031131,  2.54259571,  2.44891   ,  2.45430049,  2.4714113 ,\n",
       "          1.42933017,  2.7025302 ,  2.6672779 ,  2.62126564,  2.46964957,\n",
       "          2.11221016,  2.46522092])>,\n",
       "  'V5': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       "  array([ 0.36968143, -0.02510498,  0.75998266, -0.27456735,  1.72883164,\n",
       "          0.7510884 , -0.62125581, -0.10711584, -0.64282346, -0.48143527,\n",
       "         -0.7128195 , -1.52175088, -0.16256724,  0.36891037,  1.51083902,\n",
       "          0.6064774 ,  0.08152244,  1.74875486, -0.40433067, -0.24799022,\n",
       "          2.46336849,  0.25065122,  0.1612489 , -0.09150791, -0.25702825,\n",
       "          0.53460469, -0.72247575, -0.67044534,  0.89729999, -0.4111943 ,\n",
       "         -0.23390337, -0.40215141])>,\n",
       "  'V6': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       "  array([-0.10777626, -1.17010263, -1.4811729 ,  0.28685604,  4.40988462,\n",
       "         -0.89926234,  0.6185537 , -0.24554794,  0.6816815 ,  0.96652194,\n",
       "          1.05734349,  0.58158851,  2.24226851,  1.12063835,  2.0757781 ,\n",
       "          0.41120448, -0.92222826,  3.20521301,  0.23586158, -0.08430884,\n",
       "          4.23238433,  0.47182519,  1.09486222,  0.81259746,  1.0799948 ,\n",
       "          0.68388308,  0.17100915,  0.60544019,  1.16309887,  1.1293125 ,\n",
       "          0.26853037,  1.22221656])>,\n",
       "  'V7': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       "  array([ 0.7516099 ,  0.8616102 , -0.50968145,  0.15210975, -1.1388158 ,\n",
       "          0.88055736, -0.64414025,  0.09960314, -0.64358517, -0.68604649,\n",
       "         -0.51891076, -1.49820884, -0.23239965, -0.43389645, -0.38472857,\n",
       "          0.90565351,  0.71581416, -0.66606107, -0.00793191,  0.27925308,\n",
       "         -0.56935258, -0.04238579,  0.23198203, -0.10657152, -0.69098913,\n",
       "         -0.21785825, -0.50111896, -0.6815347 , -0.86189443, -0.76025889,\n",
       "          0.12081272, -0.57871558])>,\n",
       "  'V8': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       "  array([-0.12016626, -0.19393352,  0.54072208,  0.20087166,  1.1646445 ,\n",
       "         -0.18165031,  0.31091893, -0.04145659,  0.35430862,  0.4070323 ,\n",
       "          0.92723539,  2.13184694, -2.19934477,  0.25297756,  0.23030006,\n",
       "         -0.63004902, -0.13552179,  0.82124065,  0.21144152,  0.19069996,\n",
       "          1.25344262,  0.06651305, -0.30986027,  0.2987885 ,  0.38796181,\n",
       "         -0.56774779,  0.1176771 ,  0.34223196,  0.75672577,  0.48421147,\n",
       "          0.18692532, -0.31420672])>,\n",
       "  'V9': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       "  array([-0.42067497,  0.59200095, -0.73362339, -0.59650529, -0.02057845,\n",
       "         -0.21165709,  0.12596404, -0.86731931,  0.32571997, -0.26995177,\n",
       "         -0.65663879, -0.49955301,  2.52405096, -0.70370343, -0.3679565 ,\n",
       "         -1.00666727, -0.42316386,  1.38047193, -0.20981682, -0.51150574,\n",
       "         -0.41085038, -0.45182313, -0.06709119, -0.54155812,  0.25063606,\n",
       "         -0.24481121, -0.01586149,  0.20942002, -0.97944057, -0.09752914,\n",
       "         -0.60759385, -0.50581192])>},\n",
       " <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "# TODO 1\n",
    "# Create the datasets\n",
    "raw_train_data = # Your code goes here\n",
    "raw_val_data = # Your code goes here\n",
    "raw_test_data = # Your code goes here\n",
    "\n",
    "next(iter(raw_train_data)) # Print first batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1f4EV7V4aljW"
   },
   "source": [
    "# Build the model\n",
    "\n",
    "## Step 1: Preprocess data\n",
    "\n",
    "Let's create feature columns for each feature in the dataset. In this particular dataset, all of the columns are of type **numeric_column**, but there a number of other column types (e.g. categorical_column).\n",
    "\n",
    "You will also norm the data to center around zero so that the network converges faster. You've precalculated the means of each feature to use in this calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "38oX6ymCXClH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='Time', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function norm_data at 0x7f445e966050>, 94816.7387536405)),\n",
       " NumericColumn(key='V1', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function norm_data at 0x7f445e966050>, 0.0011219465482001268)),\n",
       " NumericColumn(key='V2', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function norm_data at 0x7f445e966050>, -0.0021445914636999603)),\n",
       " NumericColumn(key='V3', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function norm_data at 0x7f445e966050>, -0.002317402958335562)),\n",
       " NumericColumn(key='V4', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function norm_data at 0x7f445e966050>, -0.002525792169927835)),\n",
       " NumericColumn(key='V5', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function norm_data at 0x7f445e966050>, -0.002136576923287782)),\n",
       " NumericColumn(key='V6', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function norm_data at 0x7f445e966050>, -3.7586818983702983)),\n",
       " NumericColumn(key='V7', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function norm_data at 0x7f445e966050>, 0.0008135919975738768)),\n",
       " NumericColumn(key='V8', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function norm_data at 0x7f445e966050>, -0.0015535579268265718)),\n",
       " NumericColumn(key='V9', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function norm_data at 0x7f445e966050>, 0.001436137140461279)),\n",
       " NumericColumn(key='V10', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function norm_data at 0x7f445e966050>, -0.0012193712736681508)),\n",
       " NumericColumn(key='V11', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function norm_data at 0x7f445e966050>, -0.00045364970422902533)),\n",
       " NumericColumn(key='V12', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function norm_data at 0x7f445e966050>, -0.00046175444671576083)),\n",
       " NumericColumn(key='V13', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function norm_data at 0x7f445e966050>, 0.000992177789685366)),\n",
       " NumericColumn(key='V14', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function norm_data at 0x7f445e966050>, 0.002366229151475428)),\n",
       " NumericColumn(key='V15', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function norm_data at 0x7f445e966050>, 0.0006710217226762278)),\n",
       " NumericColumn(key='V16', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function norm_data at 0x7f445e966050>, 0.0010325807119864225)),\n",
       " NumericColumn(key='V17', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function norm_data at 0x7f445e966050>, 0.0002557260815835395)),\n",
       " NumericColumn(key='V18', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function norm_data at 0x7f445e966050>, -0.00020804190062322664)),\n",
       " NumericColumn(key='V19', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function norm_data at 0x7f445e966050>, -0.0005057391100818653)),\n",
       " NumericColumn(key='V20', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function norm_data at 0x7f445e966050>, -3.452114767842334e-06)),\n",
       " NumericColumn(key='V21', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function norm_data at 0x7f445e966050>, 0.00010145936326270006)),\n",
       " NumericColumn(key='V22', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function norm_data at 0x7f445e966050>, 0.0003839214074518535)),\n",
       " NumericColumn(key='V23', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function norm_data at 0x7f445e966050>, 0.00022061197469126577)),\n",
       " NumericColumn(key='V24', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function norm_data at 0x7f445e966050>, -0.00015601580596677608)),\n",
       " NumericColumn(key='V25', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function norm_data at 0x7f445e966050>, -0.0008235017846415852)),\n",
       " NumericColumn(key='V26', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function norm_data at 0x7f445e966050>, -0.0007298316615408554)),\n",
       " NumericColumn(key='V27', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function norm_data at 0x7f445e966050>, -6.898459943652376e-05)),\n",
       " NumericColumn(key='V28', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function norm_data at 0x7f445e966050>, 4.724125688297753e-05)),\n",
       " NumericColumn(key='Amount', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function norm_data at 0x7f445e966050>, 88.73235686453587))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MEANS = [94816.7387536405, 0.0011219465482001268, -0.0021445914636999603, -0.002317402958335562,\n",
    "         -0.002525792169927835, -0.002136576923287782, -3.7586818983702984, 8.135919975738768E-4,\n",
    "         -0.0015535579268265718, 0.001436137140461279, -0.0012193712736681508, -4.5364970422902533E-4,\n",
    "         -4.6175444671576083E-4, 9.92177789685366E-4, 0.002366229151475428, 6.710217226762278E-4,\n",
    "         0.0010325807119864225, 2.557260815835395E-4, -2.0804190062322664E-4, -5.057391100818653E-4,\n",
    "         -3.452114767842334E-6, 1.0145936326270006E-4, 3.839214074518535E-4, 2.2061197469126577E-4,\n",
    "         -1.5601580596677608E-4, -8.235017846415852E-4, -7.298316615408554E-4, -6.898459943652376E-5,\n",
    "         4.724125688297753E-5, 88.73235686453587]\n",
    "\n",
    "def norm_data(mean, data):\n",
    "  data = tf.cast(data, tf.float32) * 1/(2*mean)\n",
    "  return tf.reshape(data, [-1, 1])\n",
    "\n",
    "numeric_columns = []\n",
    "\n",
    "for i, feature in enumerate(FEATURES):\n",
    "# TODO 2: Your code goes here\n",
    "\n",
    "numeric_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q62gJg-tbNc9"
   },
   "source": [
    "## Step 2: Build the model\n",
    "\n",
    "Now we are ready to create a model. We will feed the columns we just created into the network. Then we will compile the model. We are including the Precision/Recall AUC metric, which is [useful for imbalanced datasets](http://pages.cs.wisc.edu/~jdavis/davisgoadrichcamera2.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TOEehaFvXCu3"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    tf.keras.layers.DenseFeatures(numeric_columns),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(# TODO 3: Your code goes here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0obFZaiCbcZW"
   },
   "source": [
    "## Step 3: Train the model\n",
    "\n",
    "There are a number of techniques to handle imbalanced data, including oversampling (generating new data in the minority class) and undersampling (reducing the data in the majority class).\n",
    "\n",
    "For the purposes of this codelab, let's use a technique that overweights the loss when misclassifying the minority class. You'll specify a class_weight parameter when training and weight \"1\" (fraud) higher, since it is much less prevalent.\n",
    "\n",
    "You will use 3 epochs (passes through the data) in this lab so training is quicker. In a real-world scenario, You'd want to run it long enough to the point where the stop seeing increases in accuracy of the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "A_VLpZFOXC3T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Amount': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'Time': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float64>, 'V1': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>, 'V10': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float64>, 'V11': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float64>, 'V12': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, 'V13': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float64>, 'V14': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float64>, 'V15': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float64>, 'V16': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=float64>, 'V17': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=float64>, 'V18': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float64>, 'V19': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float64>, 'V2': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=float64>, 'V20': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float64>, 'V21': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float64>, 'V22': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float64>, 'V23': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float64>, 'V24': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float64>, 'V25': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float64>, 'V26': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float64>, 'V27': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float64>, 'V28': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float64>, 'V3': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float64>, 'V4': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float64>, 'V5': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float64>, 'V6': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float64>, 'V7': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=float64>, 'V8': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float64>, 'V9': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Amount': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'Time': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float64>, 'V1': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>, 'V10': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float64>, 'V11': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float64>, 'V12': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, 'V13': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float64>, 'V14': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float64>, 'V15': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float64>, 'V16': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=float64>, 'V17': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=float64>, 'V18': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float64>, 'V19': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float64>, 'V2': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=float64>, 'V20': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float64>, 'V21': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float64>, 'V22': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float64>, 'V23': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float64>, 'V24': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float64>, 'V25': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float64>, 'V26': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float64>, 'V27': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float64>, 'V28': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float64>, 'V3': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float64>, 'V4': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float64>, 'V5': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float64>, 'V6': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float64>, 'V7': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=float64>, 'V8': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float64>, 'V9': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float64>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 11:40:49.370573: E tensorflow/core/framework/dataset.cc:552] Unimplemented: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-05-25 11:40:49.370632: E tensorflow/core/framework/dataset.cc:556] Unimplemented: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1/Unknown - 12s 12s/step - loss: 8215.7061 - accuracy: 0.3750 - auc: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 11:40:59.290556: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 7102 of 10000\n",
      "2022-05-25 11:40:59.326535: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:228] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   7117/Unknown - 51s 5ms/step - loss: 1548.2819 - accuracy: 0.8821 - auc: 0.0056WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Amount': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'Time': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float64>, 'V1': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>, 'V10': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float64>, 'V11': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float64>, 'V12': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, 'V13': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float64>, 'V14': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float64>, 'V15': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float64>, 'V16': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=float64>, 'V17': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=float64>, 'V18': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float64>, 'V19': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float64>, 'V2': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=float64>, 'V20': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float64>, 'V21': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float64>, 'V22': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float64>, 'V23': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float64>, 'V24': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float64>, 'V25': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float64>, 'V26': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float64>, 'V27': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float64>, 'V28': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float64>, 'V3': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float64>, 'V4': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float64>, 'V5': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float64>, 'V6': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float64>, 'V7': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=float64>, 'V8': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float64>, 'V9': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float64>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 11:41:39.231656: E tensorflow/core/framework/dataset.cc:552] Unimplemented: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-05-25 11:41:39.231730: E tensorflow/core/framework/dataset.cc:556] Unimplemented: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7122/7122 [==============================] - 57s 6ms/step - loss: 1547.2107 - accuracy: 0.8822 - auc: 0.0056 - val_loss: 22.3146 - val_accuracy: 0.9534 - val_auc: 0.0291\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 11:41:44.524025: E tensorflow/core/framework/dataset.cc:552] Unimplemented: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-05-25 11:41:44.524081: E tensorflow/core/framework/dataset.cc:556] Unimplemented: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7122/7122 [==============================] - ETA: 0s - loss: 480.7204 - accuracy: 0.9375 - auc: 0.0181"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 11:42:31.364578: E tensorflow/core/framework/dataset.cc:552] Unimplemented: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-05-25 11:42:31.364641: E tensorflow/core/framework/dataset.cc:556] Unimplemented: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7122/7122 [==============================] - 52s 6ms/step - loss: 480.7204 - accuracy: 0.9375 - auc: 0.0181 - val_loss: 7.7326 - val_accuracy: 0.9973 - val_auc: 0.2934\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 11:42:36.568942: E tensorflow/core/framework/dataset.cc:552] Unimplemented: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-05-25 11:42:36.569007: E tensorflow/core/framework/dataset.cc:556] Unimplemented: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7115/7122 [============================>.] - ETA: 0s - loss: 466.3722 - accuracy: 0.9641 - auc: 0.0316"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 11:43:23.957511: E tensorflow/core/framework/dataset.cc:552] Unimplemented: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-05-25 11:43:23.957580: E tensorflow/core/framework/dataset.cc:556] Unimplemented: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7122/7122 [==============================] - 52s 6ms/step - loss: 465.9138 - accuracy: 0.9641 - auc: 0.0316 - val_loss: 13.3608 - val_accuracy: 0.9974 - val_auc: 0.2995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4460d7e3d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASS_WEIGHT = {\n",
    "    0: 1,\n",
    "    1: 100\n",
    "}\n",
    "EPOCHS = 3\n",
    "\n",
    "train_data = raw_train_data.shuffle(10000)\n",
    "val_data = raw_val_data\n",
    "test_data = raw_test_data\n",
    "\n",
    "# Train the model using model.fit()\n",
    "# TODO 4: Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LXDgmY9ub1QE"
   },
   "source": [
    "## Step 4: Evaluate the model\n",
    "\n",
    "The evaluate() function can be applied to test data that the model has never seen to provide an objective assessment. Fortunately, we've set aside test data just for that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "UDlPNf9BXVkn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 11:43:58.601339: E tensorflow/core/framework/dataset.cc:552] Unimplemented: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-05-25 11:43:58.601398: E tensorflow/core/framework/dataset.cc:556] Unimplemented: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "889/889 [==============================] - 6s 6ms/step - loss: 11.7589 - accuracy: 0.9978 - auc: 0.3504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11.758894920349121, 0.9978189468383789, 0.3504483997821808]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "# TODO 5: Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "takoRGBeb6uC"
   },
   "source": [
    "## Step 5: Exploration\n",
    "\n",
    "In this lab, you've demonstrated how to ingest a large data set from BigQuery directly into a TensorFlow Keras model. You've also walked through all the steps of building a model. Finally, you learned a bit about how to handle imbalanced classification problems.\n",
    "\n",
    "Feel free to keep playing around with different architectures and approaches to the imbalanced dataset, to see if you can improve the accuracy!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "fraud_detection_with_tensorflow_bigquery.ipynb",
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m92",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m92"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
